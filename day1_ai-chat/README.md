🔥 День 1. Первый запрос к LLM через API

СНАЧАЛА ПОСМОТРИТЕ ВИДЕО

Напишите минимальный код, который:
👉 отправляет запрос в LLM через API
👉 получает ответ
👉 выводит его в консоль или простой интерфейс (CLI / Web)

Результат:
Код, который отправляет запрос в LLM через API и получает ответ


🔥День 5. Версии моделей

Выполните один и тот же запрос:
👉 на слабой модели
👉 на средней модели
👉 на сильной модели

(например: из начала, середины и конца списка HuggingFace)

Замерьте:
👉 время ответа
👉 количество токенов
👉 стоимость (если модель платная)

Here's the benchmark comparison of our three models:

┌──────────────────┬───────────────────────────┬───────────────────────────────┬─────────────────────────────────┐
│    Benchmark     │ Arcee Trinity Mini (Weak) │ NVIDIA Nemotron Nano (Medium) │ StepFun Step 3.5 Flash (Strong) │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ Architecture     │    3B active / 26B MoE    │      3B active / 30B MoE      │      11B active / 196B MoE      │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ MMLU             │           84.95           │               —               │              85.8               │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ MMLU-Pro         │             —             │             78.3              │                —                │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ GPQA Diamond     │           58.55           │             73.0              │                —                │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ MATH-500         │           92.10           │               —               │                —                │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ AIME 2025        │             —             │             89.1              │              99.8               │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ HumanEval        │             —             │               —               │              81.1               │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ LiveCodeBench v6 │             —             │             68.3              │              86.4               │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ SWE-Bench        │             —             │             38.8              │                —                │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ Context          │           131K            │             256K              │              256K               │
├──────────────────┼───────────────────────────┼───────────────────────────────┼─────────────────────────────────┤
│ Cost             │           Free            │             Free              │              Free               │
└──────────────────┴───────────────────────────┴───────────────────────────────┴─────────────────────────────────┘

Key takeaways:
- Step 3.5 Flash is clearly the strongest — near-perfect on AIME (99.8), best on coding (LiveCodeBench 86.4), and 3.5x more active parameters
- Nemotron Nano excels at math reasoning (AIME 89.1) and has strong long-context support (up to 1M tokens)
- Trinity Mini is competitive on MMLU (84.95) and math (MATH-500: 92.10) despite being the smallest, but weaker on GPQA (58.55)
