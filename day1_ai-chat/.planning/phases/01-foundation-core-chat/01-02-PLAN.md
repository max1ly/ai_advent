---
phase: 01-foundation-core-chat
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - app/page.tsx
  - app/components/ChatMessage.tsx
  - app/components/ChatInput.tsx
  - app/components/ChatContainer.tsx
  - app/components/ErrorMessage.tsx
  - app/globals.css
autonomous: false
must_haves:
  truths:
    - "User can type multi-line messages in an auto-resizing textarea"
    - "User can send messages by pressing Enter or clicking the Send button"
    - "User sees their sent messages displayed in a conversation thread"
    - "User sees AI responses stream in token-by-token as they are generated"
    - "User sees a loading indicator while waiting for the first AI token"
    - "User can scroll through conversation history without auto-scroll fighting"
    - "User sees markdown formatting (bold, italic, lists, headings, code blocks) in AI responses"
    - "Markdown rendering is XSS-safe (no raw HTML execution)"
    - "User sees a clear error message with a Retry button when the API fails"
  artifacts:
    - path: "app/page.tsx"
      provides: "Main chat page wiring useChat hook to all components"
      contains: "useChat"
    - path: "app/components/ChatMessage.tsx"
      provides: "Single message display with markdown rendering for assistant, plain text for user"
      contains: "ReactMarkdown"
    - path: "app/components/ChatInput.tsx"
      provides: "Auto-resizing textarea with Enter-to-send and Send button"
      contains: "TextareaAutosize"
    - path: "app/components/ChatContainer.tsx"
      provides: "Scrollable message list with smart auto-scroll"
      contains: "scrollIntoView"
    - path: "app/components/ErrorMessage.tsx"
      provides: "Error display with retry button"
      contains: "Retry"
  key_links:
    - from: "app/page.tsx"
      to: "ai/react"
      via: "useChat hook providing messages, input, handleInputChange, handleSubmit, error, status, reload"
      pattern: "useChat"
    - from: "app/page.tsx"
      to: "app/components/ChatContainer.tsx"
      via: "passes messages and status props"
      pattern: "ChatContainer.*messages"
    - from: "app/page.tsx"
      to: "app/components/ChatInput.tsx"
      via: "passes input, handleInputChange, handleSubmit, disabled state"
      pattern: "ChatInput.*input"
    - from: "app/page.tsx"
      to: "app/components/ErrorMessage.tsx"
      via: "passes error and reload callback"
      pattern: "ErrorMessage.*error"
    - from: "app/components/ChatMessage.tsx"
      to: "react-markdown"
      via: "renders assistant message content through ReactMarkdown"
      pattern: "ReactMarkdown.*remarkPlugins"
    - from: "app/components/ChatContainer.tsx"
      to: "app/components/ChatMessage.tsx"
      via: "maps over messages array to render each message"
      pattern: "messages\\.map"
---

<objective>
Build the complete chat UI with streaming display, markdown rendering, auto-scroll, and error handling.

Purpose: This is the user-facing plan that delivers the core product value — a working chat interface where users can converse with an AI. Every requirement in CHAT-01 through CHAT-06, LLM-03, CONT-01, and CONT-02 is implemented here.

Output: A fully functional chat page with 4 components (ChatContainer, ChatMessage, ChatInput, ErrorMessage) wired together via Vercel AI SDK's useChat hook.
</objective>

<execution_context>
@/Users/maxlee/.claude/get-shit-done/workflows/execute-plan.md
@/Users/maxlee/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-core-chat/01-RESEARCH.md
@.planning/phases/01-foundation-core-chat/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create chat components (ChatMessage, ChatInput, ChatContainer, ErrorMessage)</name>
  <files>
    app/components/ChatMessage.tsx
    app/components/ChatInput.tsx
    app/components/ChatContainer.tsx
    app/components/ErrorMessage.tsx
  </files>
  <action>
    Create `app/components/` directory and build four components. All are client components (need 'use client' directive since they use hooks or event handlers).

    **ChatMessage.tsx** — Renders a single message. User messages render as plain text (right-aligned, blue background). Assistant messages render through react-markdown with remark-gfm (left-aligned, gray background).

    Props: `{ role: 'user' | 'assistant'; content: string }`

    Implementation details:
    - Import ReactMarkdown from 'react-markdown' and remarkGfm from 'remark-gfm'
    - Only use ReactMarkdown for assistant messages (user messages are plain text, no need for markdown)
    - Add custom component overrides for `code` to distinguish inline code (bg-gray-100 rounded px-1 py-0.5) from code blocks (bg-gray-100 p-4 rounded-lg overflow-x-auto, wrapped in pre)
    - The code component receives `inline` as a prop — use it to switch between inline and block rendering
    - User messages: white text on blue-600 background, rounded-2xl rounded-br-md (chat bubble shape), max-w-[80%], ml-auto
    - Assistant messages: text on white/gray-50 background, rounded-2xl rounded-bl-md, max-w-[80%], mr-auto
    - Add `prose prose-sm` Tailwind typography classes to the assistant message wrapper for good default markdown styling. Install @tailwindcss/typography if not already installed: `npm install @tailwindcss/typography`. Note: With Tailwind v4, the plugin needs to be added via CSS import `@plugin "@tailwindcss/typography"` in globals.css (NOT via tailwind.config — v4 uses CSS-first configuration).
    - IMPORTANT: Do NOT use dangerouslySetInnerHTML anywhere. react-markdown renders to React elements directly (XSS-safe by design).

    **ChatInput.tsx** — Auto-resizing textarea with send button.

    Props: `{ input: string; handleInputChange: (e: React.ChangeEvent<HTMLTextAreaElement>) => void; handleSubmit: (e: React.FormEvent) => void; isLoading: boolean }`

    Implementation details:
    - Import TextareaAutosize from 'react-textarea-autosize'
    - TextareaAutosize with minRows={1}, maxRows={8}, placeholder="Type a message..."
    - Enter key submits (call handleSubmit), Shift+Enter adds newline — implement via onKeyDown handler
    - Send button: disabled when isLoading or input is empty/whitespace-only. Show a send icon or "Send" text.
    - Wrap in a form element with onSubmit={handleSubmit}
    - Style: sticky bottom, border-t, padding, flex row with gap-2. Textarea gets flex-1 with border rounded-xl padding. Button gets px-4 py-2 bg-blue-600 text-white rounded-xl, disabled:opacity-50.

    **ChatContainer.tsx** — Scrollable message list with smart auto-scroll.

    Props: `{ messages: Array<{ id: string; role: 'user' | 'assistant'; content: string }>; status: string }`

    Implementation details:
    - Use two refs: `containerRef` for the scroll container div, `bottomRef` for an empty div at the end
    - useEffect on [messages, status]: check if user is near bottom (scrollHeight - scrollTop <= clientHeight + 100). Only call bottomRef.current.scrollIntoView({ behavior: 'smooth' }) if near bottom. This prevents auto-scroll from fighting the user when they're reading history.
    - Map over messages to render ChatMessage components
    - Show loading indicator when status is 'submitted' (waiting for first token): a pulsing dot animation or "AI is thinking..." text with animate-pulse. This covers the gap between sending and receiving the first token.
    - When status is 'streaming', do NOT show a separate indicator — the streaming text itself is the indicator.
    - Empty state: when messages array is empty, show a centered welcome message like "Send a message to start chatting"
    - Style: flex-1 overflow-y-auto, padding, space-y-4 for message gaps

    **ErrorMessage.tsx** — Error display with retry.

    Props: `{ error: Error; onRetry: () => void }`

    Implementation details:
    - Red/rose background banner with error icon, error message text, and Retry button
    - Style: mx-4 mb-4 p-4 bg-red-50 border border-red-200 rounded-xl, flex items-center gap-3
    - Retry button: text-red-700 underline hover:text-red-900, or a styled button
    - Show error.message if available, otherwise "Something went wrong. Please try again."
  </action>
  <verify>
    Run `npm run build` — all four components should compile without TypeScript errors. Verify no `dangerouslySetInnerHTML` appears in any component file.
  </verify>
  <done>
    Four chat components created in app/components/ — ChatMessage (with markdown), ChatInput (with auto-resize), ChatContainer (with smart scroll), ErrorMessage (with retry). All compile without errors. No XSS-vulnerable patterns used.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire chat page with useChat hook connecting all components</name>
  <files>
    app/page.tsx
    app/globals.css
  </files>
  <action>
    Replace the placeholder `app/page.tsx` with the full chat interface.

    **page.tsx** — Main chat page (client component):

    ```
    'use client';
    ```

    Import useChat from 'ai/react' and all four components.

    Use the useChat hook which auto-connects to POST /api/chat:
    ```typescript
    const { messages, input, handleInputChange, handleSubmit, error, status, reload } = useChat();
    ```

    Layout structure (full viewport height, flex column):
    ```
    <div className="flex flex-col h-screen bg-gray-50">
      {/* Header */}
      <header> Day1 AI Chat title, minimal </header>

      {/* Messages area - takes remaining space */}
      <ChatContainer messages={messages} status={status} />

      {/* Error banner - shown conditionally above input */}
      {error && <ErrorMessage error={error} onRetry={reload} />}

      {/* Input area - fixed at bottom */}
      <ChatInput
        input={input}
        handleInputChange={handleInputChange}
        handleSubmit={handleSubmit}
        isLoading={status !== 'ready'}
      />
    </div>
    ```

    Key wiring details:
    - `useChat()` with no arguments defaults to POST /api/chat — this matches the route created in Plan 01
    - Pass `status !== 'ready'` as isLoading to disable input during streaming
    - The `reload` function from useChat retries the last message — pass it to ErrorMessage's onRetry
    - Header: simple bar with "Day1 AI Chat" text, border-b, py-3 px-4, bg-white

    **globals.css** — Ensure Tailwind typography plugin is loaded:
    - If using Tailwind v4, add `@plugin "@tailwindcss/typography";` after the Tailwind import
    - If using Tailwind v3 config style, add to plugins array in tailwind.config.ts instead
    - Check which config style create-next-app generated and use the appropriate method
    - Keep the file minimal: just Tailwind directives and the typography plugin import
  </action>
  <verify>
    Run `npm run build` — should compile without errors.

    Start dev server with `npm run dev` and verify:
    1. Page loads at localhost:3030 showing the chat interface with empty state message
    2. Textarea is visible and auto-resizes when typing multiple lines
    3. If DEEPSEEK_API_KEY is configured: type a message, press Enter, verify streaming response appears token-by-token with markdown formatting
    4. Check browser console for no React errors or warnings
  </verify>
  <done>
    Chat page wires useChat hook to all four components. Full chat flow works: type message, send via Enter or button, see streaming AI response with markdown rendering, see error with retry on failure, smart auto-scroll preserves reading position.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify complete streaming chat interface end-to-end</name>
  <action>
    Human verifies the complete streaming chat interface works correctly by testing all user-facing behaviors.

    What was built:
    - Auto-resizing textarea input (Enter sends, Shift+Enter for newline)
    - Send button (disabled during streaming)
    - Messages displayed in conversation thread (user right, AI left)
    - AI responses stream token-by-token
    - Loading indicator before first token
    - Markdown rendering in AI responses (code blocks, lists, bold text)
    - Error handling with retry button
    - Smart auto-scroll (scrolls during streaming, but not if user scrolled up)

    Verification steps:

    Prerequisites: Set your DeepSeek API key in `.env.local` (DEEPSEEK_API_KEY=sk-your-key)

    1. Start dev server: `npm run dev`
    2. Open http://localhost:3030
    3. Verify empty state shows welcome message
    4. Type "Hello" and press Enter — verify message appears on the right, loading indicator shows, then AI response streams in on the left
    5. Ask "Write a Python function to reverse a string with comments" — verify code block renders with proper formatting
    6. Ask "List 5 benefits of TypeScript" — verify numbered/bulleted list renders properly
    7. Send several messages to fill the screen — verify auto-scroll works during streaming
    8. Scroll up while AI is responding — verify it does NOT force you back to the bottom
    9. Try sending with the Send button (not just Enter)
    10. Verify Shift+Enter adds a newline instead of sending
    11. Check that the textarea grows with multiple lines of input
  </action>
  <verify>Human confirms all 11 verification steps pass</verify>
  <done>User has approved the chat interface as working correctly</done>
  <resume-signal>Type "approved" to complete Phase 1, or describe any issues to fix</resume-signal>
</task>

</tasks>

<verification>
Requirements coverage check:
- CHAT-01: Auto-resizing textarea (ChatInput + react-textarea-autosize) [CHECK]
- CHAT-02: Send via Enter or Send button (ChatInput onKeyDown + form submit) [CHECK]
- CHAT-03: Messages in conversation thread (ChatContainer + ChatMessage) [CHECK]
- CHAT-04: Token-by-token streaming (useChat + ChatContainer) [CHECK]
- CHAT-05: Loading indicator before first token (ChatContainer status='submitted') [CHECK]
- CHAT-06: Scrollable conversation history (ChatContainer smart scroll) [CHECK]
- LLM-01: Server-side API route, key not in browser (Plan 01 route.ts) [CHECK - via Plan 01]
- LLM-02: SSE streaming (Plan 01 streamText + toDataStreamResponse) [CHECK - via Plan 01]
- LLM-03: Error message with retry (ErrorMessage + useChat error/reload) [CHECK]
- LLM-04: Configurable model via env var (Plan 01 DEEPSEEK_MODEL) [CHECK - via Plan 01]
- CONT-01: Markdown formatting (ChatMessage + react-markdown + remark-gfm) [CHECK]
- CONT-02: XSS-safe rendering (react-markdown, no dangerouslySetInnerHTML) [CHECK]
</verification>

<success_criteria>
- All 4 components render without errors
- useChat hook connects to /api/chat and manages message state
- User messages appear immediately in the thread
- AI responses stream in visually token-by-token
- Loading indicator visible between send and first token
- Markdown formatting works (code blocks, lists, bold, headings)
- No dangerouslySetInnerHTML in any component (XSS-safe)
- Error state shows message and retry button
- Auto-scroll works during streaming but respects user scroll position
- Human verification confirms end-to-end chat flow works
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-core-chat/01-02-SUMMARY.md`
</output>
